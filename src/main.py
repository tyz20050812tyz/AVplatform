import streamlit as st
import sqlite3
import os
from datetime import datetime
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from PIL import Image
import yaml
import json
import cv2
import numpy as np

# å¯¼å…¥è®¤è¯æ¨¡å—
from auth import check_authentication, show_auth_page, show_user_info, init_auth_database

try:
    import open3d as o3d
    OPEN3D_AVAILABLE = True
except ImportError:
    OPEN3D_AVAILABLE = False
    st.warning("âš ï¸ Open3Dåº“æœªå®‰è£…ï¼Œç‚¹äº‘å¯è§†åŒ–åŠŸèƒ½å°†å—é™ã€‚è¯·è¿è¡Œ: pip install open3d")

try:
    import laspy
    LASPY_AVAILABLE = True
except ImportError:
    LASPY_AVAILABLE = False

def load_point_cloud(file_path):
    """åŠ è½½ç‚¹äº‘æ•°æ®"""
    try:
        if file_path.endswith('.pcd'):
            if OPEN3D_AVAILABLE:
                pcd = o3d.io.read_point_cloud(file_path)
                points = np.asarray(pcd.points)
                colors = np.asarray(pcd.colors) if pcd.has_colors() else None
                return points, colors
            else:
                st.error("ğŸš« éœ€è¦å®‰è£… Open3D åº“æ¥è¯»å– PCD æ–‡ä»¶")
                return None, None
        
        elif file_path.endswith('.las') or file_path.endswith('.laz'):
            if LASPY_AVAILABLE:
                las_file = laspy.read(file_path)
                points = np.vstack([las_file.x, las_file.y, las_file.z]).T
                colors = None
                if hasattr(las_file, 'red') and hasattr(las_file, 'green') and hasattr(las_file, 'blue'):
                    colors = np.vstack([las_file.red, las_file.green, las_file.blue]).T / 65535.0
                return points, colors
            else:
                st.error("ğŸš« éœ€è¦å®‰è£… laspy åº“æ¥è¯»å– LAS/LAZ æ–‡ä»¶")
                return None, None
        
        elif file_path.endswith('.txt') or file_path.endswith('.xyz'):
            # ç®€å•çš„æ–‡æœ¬æ ¼å¼ç‚¹äº‘æ•°æ®
            data = np.loadtxt(file_path)
            if data.shape[1] >= 3:
                points = data[:, :3]
                colors = data[:, 3:6] if data.shape[1] >= 6 else None
                return points, colors
            else:
                st.error("ğŸš« æ–‡æœ¬æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œè‡³å°‘éœ€è¦ 3 åˆ—ï¼ˆX, Y, Zï¼‰")
                return None, None
        
        else:
            st.error(f"ğŸš« ä¸æ”¯æŒçš„ç‚¹äº‘æ–‡ä»¶æ ¼å¼: {os.path.splitext(file_path)[1]}")
            return None, None
    
    except Exception as e:
        st.error(f"ğŸš« åŠ è½½ç‚¹äº‘æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None, None

def visualize_single_pointcloud(file_path):
    """å•ä¸ªç‚¹äº‘æ–‡ä»¶å¯è§†åŒ–"""
    st.write(f"ğŸ“„ **æ–‡ä»¶**: {os.path.basename(file_path)}")
    
    with st.spinner("ğŸ”„ æ­£åœ¨åŠ è½½ç‚¹äº‘æ•°æ®..."):
        points, colors = load_point_cloud(file_path)
    
    if points is None:
        return
    
    # æ˜¾ç¤ºç‚¹äº‘ç»Ÿè®¡ä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ğŸ“Š ç‚¹æ•°é‡", f"{len(points):,}")
    with col2:
        st.metric("ğŸ“ XèŒƒå›´", f"{points[:, 0].min():.2f} ~ {points[:, 0].max():.2f}")
    with col3:
        st.metric("ğŸ“ YèŒƒå›´", f"{points[:, 1].min():.2f} ~ {points[:, 1].max():.2f}")
    with col4:
        st.metric("ğŸ“ ZèŒƒå›´", f"{points[:, 2].min():.2f} ~ {points[:, 2].max():.2f}")
    
    # å¯è§†åŒ–å‚æ•°è®¾ç½®
    st.subheader("âš™ï¸ å¯è§†åŒ–å‚æ•°")
    col1, col2 = st.columns(2)
    
    with col1:
        # é‡‡æ ·å‚æ•°
        max_points = st.slider("ğŸ¯ æœ€å¤§æ˜¾ç¤ºç‚¹æ•°", 1000, min(100000, len(points)), 
                               min(10000, len(points)), 
                               help="ä¸ºäº†æ€§èƒ½è€ƒè™‘ï¼Œå»ºè®®ä¸è¶…è¿‡ 100,000 ä¸ªç‚¹")
        
        # ç‚¹å¤§å°
        point_size = st.slider("ğŸ”´ ç‚¹å¤§å°", 1, 10, 3)
        
    with col2:
        # é¢œè‰²æ˜ å°„æ–¹å¼
        color_mode = st.selectbox(
            "ğŸ¨ é¢œè‰²æ˜ å°„",
            ["é«˜åº¦ (Z)", "åŸå§‹é¢œè‰²", "å‡åŒ€é¢œè‰²"],
            help="é€‰æ‹©ç‚¹äº‘çš„é¢œè‰²æ˜¾ç¤ºæ–¹å¼"
        )
        
        # è§†è§’é€‰æ‹©
        view_mode = st.selectbox(
            "ğŸ‘ï¸ è§†è§’æ¨¡å¼",
            ["3D è§†è§’", "ä»ä¸Šå‘ä¸‹ (XY)", "ä»å‰å‘å (XZ)", "ä»å·¦å‘å³ (YZ)"]
        )
    
    # é‡‡æ ·ç‚¹äº‘æ•°æ®
    if len(points) > max_points:
        indices = np.random.choice(len(points), max_points, replace=False)
        sampled_points = points[indices]
        sampled_colors = colors[indices] if colors is not None else None
    else:
        sampled_points = points
        sampled_colors = colors
    
    # å‡†å¤‡é¢œè‰²æ•°æ®
    if color_mode == "é«˜åº¦ (Z)":
        color_values = sampled_points[:, 2]
        colorscale = 'Viridis'
    elif color_mode == "åŸå§‹é¢œè‰²" and sampled_colors is not None:
        color_values = [f'rgb({int(r*255)},{int(g*255)},{int(b*255)})' 
                       for r, g, b in sampled_colors]
        colorscale = None
    else:
        color_values = 'blue'
        colorscale = None
    
    # åˆ›å»º 3D æ•£ç‚¹å›¾
    fig = go.Figure(data=[go.Scatter3d(
        x=sampled_points[:, 0],
        y=sampled_points[:, 1],
        z=sampled_points[:, 2],
        mode='markers',
        marker=dict(
            size=point_size,
            color=color_values,
            colorscale=colorscale,
            opacity=0.8,
            colorbar=dict(title="é«˜åº¦") if color_mode == "é«˜åº¦ (Z)" else None
        ),
        text=[f'X: {x:.2f}<br>Y: {y:.2f}<br>Z: {z:.2f}' 
              for x, y, z in sampled_points[:100]],  # åªä¸ºå‰100ä¸ªç‚¹æ·»åŠ æ‚¬åœä¿¡æ¯
        hovertemplate='%{text}<extra></extra>'
    )])
    
    # è®¾ç½®å¸ƒå±€
    camera_settings = {
        "3D è§†è§’": dict(eye=dict(x=1.5, y=1.5, z=1.5)),
        "ä»ä¸Šå‘ä¸‹ (XY)": dict(eye=dict(x=0, y=0, z=3)),
        "ä»å‰å‘å (XZ)": dict(eye=dict(x=0, y=3, z=0)),
        "ä»å·¦å‘å³ (YZ)": dict(eye=dict(x=3, y=0, z=0))
    }
    
    fig.update_layout(
        title=f'ğŸŒŒ ç‚¹äº‘å¯è§†åŒ–: {os.path.basename(file_path)}',
        scene=dict(
            xaxis_title='X',
            yaxis_title='Y',
            zaxis_title='Z',
            camera=camera_settings.get(view_mode, camera_settings["ä¸‰ç»´è§†è§’"]),
            aspectmode='cube'
        ),
        height=600,
        margin=dict(r=0, b=0, l=0, t=40)
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
    with st.expander("ğŸ“Š è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"):
        col1, col2 = st.columns(2)
        with col1:
            st.write("**åŸºæœ¬ä¿¡æ¯**")
            st.write(f"- åŸå§‹ç‚¹æ•°: {len(points):,}")
            st.write(f"- æ˜¾ç¤ºç‚¹æ•°: {len(sampled_points):,}")
            st.write(f"- æ–‡ä»¶å¤§å°: {os.path.getsize(file_path):,} bytes")
            st.write(f"- æœ‰æ— é¢œè‰²: {'Yes' if colors is not None else 'No'}")
        
        with col2:
            st.write("**åæ ‡ç»Ÿè®¡**")
            for i, axis in enumerate(['X', 'Y', 'Z']):
                st.write(f"- {axis} è½´: [{points[:, i].min():.3f}, {points[:, i].max():.3f}]")
                st.write(f"  å¹³å‡å€¼: {points[:, i].mean():.3f}, æ ‡å‡†å·®: {points[:, i].std():.3f}")

def visualize_multiple_pointclouds(file_paths):
    """å¤šä¸ªç‚¹äº‘æ–‡ä»¶å¯è§†åŒ–"""
    st.subheader(f"ğŸ“‹ å¤šç‚¹äº‘æ–‡ä»¶å¯¹æ¯” ({len(file_paths)} ä¸ªæ–‡ä»¶)")
    
    # æ˜¾ç¤ºæ¨¡å¼é€‰æ‹©
    display_mode = st.radio(
        "ğŸ“Š æ˜¾ç¤ºæ¨¡å¼",
        ["å¹¶æ’æ˜¾ç¤º", "å åŠ æ˜¾ç¤º", "å¯¹æ¯”åˆ†æ"],
        horizontal=True
    )
    
    if display_mode == "å¹¶æ’æ˜¾ç¤º":
        # é€‰æ‹©è¦æ˜¾ç¤ºçš„æ–‡ä»¶
        selected_files = st.multiselect(
            "ğŸ“ é€‰æ‹©è¦æ˜¾ç¤ºçš„æ–‡ä»¶",
            file_paths,
            default=file_paths[:2],  # é»˜è®¤é€‰æ‹©å‰ä¸¤ä¸ª
            format_func=lambda x: os.path.basename(x)
        )
        
        if selected_files:
            cols = st.columns(min(len(selected_files), 2))
            for i, file_path in enumerate(selected_files):
                with cols[i % 2]:
                    st.write(f"**{os.path.basename(file_path)}**")
                    with st.spinner(f"åŠ è½½ {os.path.basename(file_path)}..."):
                        points, colors = load_point_cloud(file_path)
                    
                    if points is not None:
                        # ç®€åŒ–ç‰ˆå¯è§†åŒ–
                        max_points = 5000  # å¹¶æ’æ˜¾ç¤ºæ—¶å‡å°‘ç‚¹æ•°
                        if len(points) > max_points:
                            indices = np.random.choice(len(points), max_points, replace=False)
                            sampled_points = points[indices]
                        else:
                            sampled_points = points
                        
                        fig = go.Figure(data=[go.Scatter3d(
                            x=sampled_points[:, 0],
                            y=sampled_points[:, 1],
                            z=sampled_points[:, 2],
                            mode='markers',
                            marker=dict(
                                size=2,
                                color=sampled_points[:, 2],
                                colorscale='Viridis',
                                opacity=0.7
                            )
                        )])
                        
                        fig.update_layout(
                            title=os.path.basename(file_path),
                            scene=dict(
                                xaxis_title='X',
                                yaxis_title='Y',
                                zaxis_title='Z',
                                aspectmode='cube'
                            ),
                            height=400,
                            margin=dict(r=0, b=0, l=0, t=40)
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        st.metric("ğŸ“Š ç‚¹æ•°", f"{len(points):,}")
    
    elif display_mode == "å åŠ æ˜¾ç¤º":
        # åœ¨ä¸€ä¸ªå›¾ä¸­æ˜¾ç¤ºå¤šä¸ªç‚¹äº‘
        selected_files = st.multiselect(
            "ğŸ“ é€‰æ‹©è¦å åŠ æ˜¾ç¤ºçš„æ–‡ä»¶",
            file_paths,
            default=file_paths[:3],  # é»˜è®¤é€‰æ‹©å‰ä¸‰ä¸ª
            format_func=lambda x: os.path.basename(x)
        )
        
        if selected_files:
            max_points_per_file = st.slider(
                "ğŸ¯ æ¯ä¸ªæ–‡ä»¶æœ€å¤§ç‚¹æ•°", 
                100, 5000, 2000,
                help="ä¸ºäº†æ€§èƒ½è€ƒè™‘ï¼Œé™åˆ¶æ¯ä¸ªæ–‡ä»¶çš„æ˜¾ç¤ºç‚¹æ•°"
            )
            
            fig = go.Figure()
            colors_palette = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']
            
            total_points = 0
            for i, file_path in enumerate(selected_files):
                with st.spinner(f"åŠ è½½ {os.path.basename(file_path)}..."):
                    points, colors = load_point_cloud(file_path)
                
                if points is not None:
                    # é‡‡æ ·
                    if len(points) > max_points_per_file:
                        indices = np.random.choice(len(points), max_points_per_file, replace=False)
                        sampled_points = points[indices]
                    else:
                        sampled_points = points
                    
                    # ä¸ºä¸åŒæ–‡ä»¶ä½¿ç”¨ä¸åŒé¢œè‰²
                    color = colors_palette[i % len(colors_palette)]
                    
                    fig.add_trace(go.Scatter3d(
                        x=sampled_points[:, 0],
                        y=sampled_points[:, 1],
                        z=sampled_points[:, 2],
                        mode='markers',
                        marker=dict(
                            size=2,
                            color=color,
                            opacity=0.6
                        ),
                        name=os.path.basename(file_path)
                    ))
                    
                    total_points += len(sampled_points)
            
            fig.update_layout(
                title=f'ğŸŒŒ å¤šç‚¹äº‘å åŠ æ˜¾ç¤º (æ€»è®¡ {total_points:,} ä¸ªç‚¹)',
                scene=dict(
                    xaxis_title='X',
                    yaxis_title='Y',
                    zaxis_title='Z',
                    aspectmode='cube'
                ),
                height=700,
                margin=dict(r=0, b=0, l=0, t=40)
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    else:  # å¯¹æ¯”åˆ†æ
        st.subheader("ğŸ“Š ç‚¹äº‘æ•°æ®å¯¹æ¯”åˆ†æ")
        
        # åŠ è½½æ‰€æœ‰ç‚¹äº‘çš„ç»Ÿè®¡ä¿¡æ¯
        stats_data = []
        for file_path in file_paths:
            with st.spinner(f"åˆ†æ {os.path.basename(file_path)}..."):
                points, colors = load_point_cloud(file_path)
            
            if points is not None:
                stats = {
                    'æ–‡ä»¶å': os.path.basename(file_path),
                    'ç‚¹æ•°é‡': len(points),
                    'XèŒƒå›´': f"{points[:, 0].min():.2f} ~ {points[:, 0].max():.2f}",
                    'YèŒƒå›´': f"{points[:, 1].min():.2f} ~ {points[:, 1].max():.2f}",
                    'ZèŒƒå›´': f"{points[:, 2].min():.2f} ~ {points[:, 2].max():.2f}",
                    'Xå¹³å‡': f"{points[:, 0].mean():.3f}",
                    'Yå¹³å‡': f"{points[:, 1].mean():.3f}",
                    'Zå¹³å‡': f"{points[:, 2].mean():.3f}",
                    'æ–‡ä»¶å¤§å°(MB)': f"{os.path.getsize(file_path) / 1024 / 1024:.2f}",
                    'æœ‰æ— é¢œè‰²': 'Yes' if colors is not None else 'No'
                }
                stats_data.append(stats)
        
        if stats_data:
            # æ˜¾ç¤ºå¯¹æ¯”è¡¨æ ¼
            df_stats = pd.DataFrame(stats_data)
            st.dataframe(df_stats, use_container_width=True)
            
            # ç‚¹æ•°é‡å¯¹æ¯”å›¾
            col1, col2 = st.columns(2)
            
            with col1:
                fig_points = px.bar(
                    df_stats, 
                    x='æ–‡ä»¶å', 
                    y='ç‚¹æ•°é‡',
                    title='ğŸ“Š ç‚¹æ•°é‡å¯¹æ¯”'
                )
                fig_points.update_layout(xaxis_tickangle=45)
                st.plotly_chart(fig_points, use_container_width=True)
            
            with col2:
                # æ–‡ä»¶å¤§å°å¯¹æ¯”
                df_stats['æ–‡ä»¶å¤§å°æ•°å€¼'] = df_stats['æ–‡ä»¶å¤§å°(MB)'].astype(float)
                fig_size = px.bar(
                    df_stats, 
                    x='æ–‡ä»¶å', 
                    y='æ–‡ä»¶å¤§å°æ•°å€¼',
                    title='ğŸ’¾ æ–‡ä»¶å¤§å°å¯¹æ¯” (MB)'
                )
                fig_size.update_layout(xaxis_tickangle=45)
                st.plotly_chart(fig_size, use_container_width=True)

def init_database():
    """åˆå§‹åŒ–SQLiteæ•°æ®åº“"""
    conn = sqlite3.connect('data.db')
    c = conn.cursor()
    
    # åˆ›å»ºæ•°æ®é›†è¡¨
    c.execute('''
        CREATE TABLE IF NOT EXISTS datasets (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            description TEXT,
            upload_time TEXT,
            file_count INTEGER DEFAULT 0,
            file_paths TEXT
        )
    ''')
    
    conn.commit()
    conn.close()
    """åˆå§‹åŒ–SQLiteæ•°æ®åº“"""
    conn = sqlite3.connect('data.db')
    c = conn.cursor()
    
    # åˆ›å»ºæ•°æ®é›†è¡¨
    c.execute('''
        CREATE TABLE IF NOT EXISTS datasets (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            description TEXT,
            upload_time TEXT,
            file_count INTEGER DEFAULT 0,
            file_paths TEXT
        )
    ''')
    
    conn.commit()
    conn.close()

def show_homepage():
    """æ˜¾ç¤ºé¦–é¡µ"""
    st.title("ğŸš— æ— äººé©¾é©¶æ•°æ®ç®¡ç†å¹³å°")
    
    # å¹³å°ä»‹ç»
    st.markdown("""
    ## æ¬¢è¿ä½¿ç”¨æ— äººé©¾é©¶æ•°æ®ç®¡ç†å¹³å° 
    
    è¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºç®¡ç†å’Œå…±äº«æ— äººé©¾é©¶ç›¸å…³å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®çš„å¹³å°ï¼Œæ”¯æŒï¼š
    
    ### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½
    - ğŸ“¤ **æ•°æ®ä¸Šä¼ **: æ”¯æŒæ¿€å…‰é›·è¾¾ã€æ‘„åƒå¤´ã€GPSã€IMUç­‰ä¼ æ„Ÿå™¨æ•°æ®
    - ğŸ“ **æ•°æ®æµè§ˆ**: ä¾¿æ·çš„æ•°æ®é›†ç®¡ç†å’Œæ–‡ä»¶æµè§ˆ
    - ğŸ“ˆ **æ•°æ®å¯è§†åŒ–**: ç›´è§‚çš„æ•°æ®å¯è§†åŒ–å’Œåˆ†æå·¥å…·
    
    ### ğŸ“Š æ”¯æŒçš„æ•°æ®æ ¼å¼
    - **ROSæ•°æ®**: .bag
    - **ç‚¹äº‘æ•°æ®**: .pcd
    - **å›¾åƒæ•°æ®**: .png, .jpg
    - **é…ç½®æ–‡ä»¶**: .yaml, .yml
    - **ä¼ æ„Ÿå™¨æ•°æ®**: .csv, .json
    
    ### ğŸ¯ ç›®æ ‡ç”¨æˆ·
    - è‡ªåŠ¨é©¾é©¶ç ”ç©¶äººå‘˜
    - é«˜æ ¡å­¦ç”Ÿå’Œæ•™å¸ˆ  
    - ç®—æ³•å·¥ç¨‹å¸ˆ
    - æ•°æ®ç§‘å­¦å®¶
    """)
    
    # ç»Ÿè®¡ä¿¡æ¯
    conn = sqlite3.connect('data.db')
    c = conn.cursor()
    c.execute("SELECT COUNT(*) FROM datasets")
    dataset_count = c.fetchone()[0]
    conn.close()
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ•°æ®é›†æ€»æ•°", dataset_count)
    with col2:
        st.metric("æ”¯æŒæ ¼å¼", "6ç§")
    with col3:
        st.metric("åœ¨çº¿ç”¨æˆ·", "1")

def show_upload_page():
    """æ˜¾ç¤ºæ•°æ®ä¸Šä¼ é¡µé¢"""
    st.title("ğŸ“¤ æ•°æ®ä¸Šä¼ ")
    
    # æ•°æ®é›†ä¿¡æ¯
    dataset_name = st.text_input("æ•°æ®é›†åç§°", placeholder="è¯·è¾“å…¥æ•°æ®é›†åç§°")
    dataset_desc = st.text_area("æ•°æ®é›†æè¿°", placeholder="è¯·æè¿°æ•°æ®é›†çš„å†…å®¹å’Œç”¨é€”")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "é€‰æ‹©æ–‡ä»¶",
        accept_multiple_files=True,
        type=['bag', 'pcd', 'png', 'jpg', 'yaml', 'yml', 'csv', 'json'],
        help="æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š.bag, .pcd, .png, .jpg, .yaml, .yml, .csv, .json"
    )
    
    if uploaded_files:
        st.subheader("æ–‡ä»¶é¢„è§ˆ")
        for file in uploaded_files:
            with st.expander(f"ğŸ“„ {file.name}"):
                st.write(f"æ–‡ä»¶å¤§å°: {file.size} bytes")
                st.write(f"æ–‡ä»¶ç±»å‹: {file.type}")
    
    if st.button("ä¸Šä¼ æ•°æ®é›†", type="primary") and dataset_name and uploaded_files:
        with st.spinner("æ­£åœ¨ä¸Šä¼ æ–‡ä»¶..."):
            try:
                # åˆ›å»ºå­˜å‚¨ç›®å½•
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                dataset_dir = f"datasets/{dataset_name}_{timestamp}"
                os.makedirs(dataset_dir, exist_ok=True)
                
                # ä¿å­˜æ–‡ä»¶
                file_paths = []
                for file in uploaded_files:
                    file_path = os.path.join(dataset_dir, file.name)
                    with open(file_path, "wb") as f:
                        f.write(file.getvalue())
                    file_paths.append(file_path)
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                conn = sqlite3.connect('data.db')
                c = conn.cursor()
                c.execute('''
                    INSERT INTO datasets (name, description, upload_time, file_count, file_paths)
                    VALUES (?, ?, ?, ?, ?)
                ''', (
                    dataset_name,
                    dataset_desc,
                    datetime.now().isoformat(),
                    len(file_paths),
                    ",".join(file_paths)
                ))
                conn.commit()
                conn.close()
                
                st.success(f"âœ… ä¸Šä¼ æˆåŠŸï¼å…±{len(file_paths)}ä¸ªæ–‡ä»¶")
                st.balloons()
                
            except Exception as e:
                st.error(f"ä¸Šä¼ å¤±è´¥: {str(e)}")

def show_browse_page():
    """æ˜¾ç¤ºæ•°æ®æµè§ˆé¡µé¢"""
    st.title("ğŸ“ æ•°æ®æµè§ˆ")
    
    # ä»æ•°æ®åº“è·å–æ•°æ®é›†åˆ—è¡¨
    conn = sqlite3.connect('data.db')
    datasets = pd.read_sql_query("SELECT * FROM datasets ORDER BY upload_time DESC", conn)
    conn.close()
    
    if len(datasets) == 0:
        st.info("æš‚æ— æ•°æ®é›†ï¼Œè¯·å…ˆä¸Šä¼ æ•°æ®")
        return
    
    # æœç´¢åŠŸèƒ½
    search_term = st.text_input("ğŸ” æœç´¢æ•°æ®é›†", placeholder="è¾“å…¥æ•°æ®é›†åç§°è¿›è¡Œæœç´¢")
    if search_term:
        datasets = datasets[datasets['name'].str.contains(search_term, case=False, na=False)]
    
    # æ˜¾ç¤ºæ•°æ®é›†åˆ—è¡¨
    for _, dataset in datasets.iterrows():
        with st.expander(f"ğŸ“Š {dataset['name']} ({dataset['file_count']} ä¸ªæ–‡ä»¶)"):
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.write(f"**æè¿°**: {dataset['description'] or 'æ— æè¿°'}")
                st.write(f"**ä¸Šä¼ æ—¶é—´**: {pd.to_datetime(dataset['upload_time']).strftime('%Y-%m-%d %H:%M:%S')}")
                
                # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
                file_paths_str = dataset['file_paths']
                if file_paths_str is not None and str(file_paths_str).strip():
                    file_paths = str(file_paths_str).split(",")
                    st.write("**æ–‡ä»¶åˆ—è¡¨**:")
                    for file_path in file_paths:
                        if os.path.exists(file_path):
                            file_size = os.path.getsize(file_path)
                            st.write(f"  - {os.path.basename(file_path)} ({file_size} bytes)")
                        else:
                            st.write(f"  - {os.path.basename(file_path)} (æ–‡ä»¶ä¸å­˜åœ¨)")
            
            with col2:
                if st.button(f"æŸ¥çœ‹è¯¦æƒ…", key=f"view_{dataset['id']}"):
                    st.session_state.selected_dataset_id = dataset['id']
                if st.button(f"åˆ é™¤æ•°æ®é›†", key=f"delete_{dataset['id']}", type="secondary"):
                    if st.session_state.get(f"confirm_delete_{dataset['id']}", False):
                        delete_dataset(dataset['id'])
                        st.rerun()
                    else:
                        st.session_state[f"confirm_delete_{dataset['id']}"] = True
                        st.warning("å†æ¬¡ç‚¹å‡»ç¡®è®¤åˆ é™¤")

def show_visualization_page():
    """æ˜¾ç¤ºæ•°æ®å¯è§†åŒ–é¡µé¢"""
    st.title("ğŸ“ˆ æ•°æ®å¯è§†åŒ–")
    
    # è·å–æ•°æ®é›†åˆ—è¡¨
    conn = sqlite3.connect('data.db')
    datasets = pd.read_sql_query("SELECT id, name FROM datasets", conn)
    conn.close()
    
    if len(datasets) == 0:
        st.info("æš‚æ— æ•°æ®é›†å¯è§†åŒ–")
        return
    
    # é€‰æ‹©æ•°æ®é›†
    dataset_options = dict(zip(datasets['id'], datasets['name']))
    selected_dataset = st.selectbox(
        "é€‰æ‹©æ•°æ®é›†",
        options=list(dataset_options.keys()),
        format_func=lambda x: dataset_options[x]
    )
    
    if selected_dataset:
        # è·å–é€‰ä¸­æ•°æ®é›†çš„æ–‡ä»¶
        conn = sqlite3.connect('data.db')
        c = conn.cursor()
        c.execute("SELECT file_paths FROM datasets WHERE id = ?", (selected_dataset,))
        result = c.fetchone()
        conn.close()
        
        if result and result[0]:
            file_paths = str(result[0]).split(",")
            
            # æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç±»
            image_files = [f for f in file_paths if f.endswith(('.png', '.jpg', '.jpeg'))]
            csv_files = [f for f in file_paths if f.endswith('.csv')]
            yaml_files = [f for f in file_paths if f.endswith(('.yaml', '.yml'))]
            json_files = [f for f in file_paths if f.endswith('.json')]
            pcd_files = [f for f in file_paths if f.endswith('.pcd')]
            bag_files = [f for f in file_paths if f.endswith('.bag')]
            
            # æ˜¾ç¤ºå›¾åƒæ•°æ®
            if image_files:
                st.subheader("ğŸ–¼ï¸ å›¾åƒæ•°æ®")
                cols = st.columns(3)
                for i, img_path in enumerate(image_files[:9]):  # æœ€å¤šæ˜¾ç¤º9å¼ 
                    with cols[i % 3]:
                        if os.path.exists(img_path):
                            try:
                                image = Image.open(img_path)
                                st.image(image, caption=os.path.basename(img_path), use_column_width=True)
                            except Exception as e:
                                st.error(f"æ— æ³•æ˜¾ç¤ºå›¾åƒ: {e}")
            
            # æ˜¾ç¤ºCSVæ•°æ®
            if csv_files:
                st.subheader("ğŸ“Š æ•°æ®æ–‡ä»¶")
                for csv_file in csv_files:
                    if os.path.exists(csv_file):
                        try:
                            df = pd.read_csv(csv_file)
                            st.write(f"**æ–‡ä»¶**: {os.path.basename(csv_file)}")
                            st.write(f"**æ•°æ®å½¢çŠ¶**: {df.shape}")
                            st.dataframe(df.head(100))  # åªæ˜¾ç¤ºå‰100è¡Œ
                            
                            # ç®€å•ç»Ÿè®¡å›¾è¡¨
                            numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
                            if len(numeric_cols) >= 2:
                                col1, col2 = st.columns(2)
                                with col1:
                                    fig = px.scatter(df, x=numeric_cols[0], y=numeric_cols[1])
                                    st.plotly_chart(fig, use_container_width=True)
                                with col2:
                                    fig = px.histogram(df, x=numeric_cols[0])
                                    st.plotly_chart(fig, use_container_width=True)
                        except Exception as e:
                            st.error(f"æ— æ³•è¯»å–CSVæ–‡ä»¶: {e}")
            
            # æ˜¾ç¤ºYAMLé…ç½®
            if yaml_files:
                st.subheader("âš™ï¸ é…ç½®æ–‡ä»¶")
                for yaml_file in yaml_files:
                    if os.path.exists(yaml_file):
                        try:
                            with open(yaml_file, 'r', encoding='utf-8') as f:
                                yaml_data = yaml.safe_load(f)
                            st.write(f"**æ–‡ä»¶**: {os.path.basename(yaml_file)}")
                            st.json(yaml_data)
                        except Exception as e:
                            st.error(f"æ— æ³•è¯»å–YAMLæ–‡ä»¶: {e}")
            
            # æ˜¾ç¤ºJSONæ•°æ®
            if json_files:
                st.subheader("ğŸ“‹ JSONæ•°æ®")
                for json_file in json_files:
                    if os.path.exists(json_file):
                        try:
                            with open(json_file, 'r', encoding='utf-8') as f:
                                json_data = json.load(f)
                            st.write(f"**æ–‡ä»¶**: {os.path.basename(json_file)}")
                            st.json(json_data)
                        except Exception as e:
                            st.error(f"æ— æ³•è¯»å–JSONæ–‡ä»¶: {e}")
            
            # æ˜¾ç¤ºç‚¹äº‘æ•°æ®
            if pcd_files:
                st.subheader("ğŸ“¡ ç‚¹äº‘æ•°æ®")
                
                # å¯è§†åŒ–æ¨¡å¼é€‰æ‹©
                if len(pcd_files) == 1:
                    # å•ä¸ªæ–‡ä»¶ç›´æ¥å¯è§†åŒ–
                    visualize_single_pointcloud(pcd_files[0])
                else:
                    # å¤šä¸ªæ–‡ä»¶æä¾›é€‰æ‹©
                    viz_mode = st.radio(
                        "ğŸ¨ å¯è§†åŒ–æ¨¡å¼",
                        ["å•ä¸ªæ–‡ä»¶", "å¤šæ–‡ä»¶å¯¹æ¯”"],
                        key=f"viz_mode_{selected_dataset}",
                        horizontal=True
                    )
                    
                    if viz_mode == "å•ä¸ªæ–‡ä»¶":
                        # é€‰æ‹©å•ä¸ªæ–‡ä»¶è¿›è¡Œè¯¦ç»†å¯è§†åŒ–
                        selected_pcd = st.selectbox(
                            "ğŸ“ é€‰æ‹©ç‚¹äº‘æ–‡ä»¶",
                            pcd_files,
                            format_func=lambda x: os.path.basename(x),
                            key=f"pcd_select_{selected_dataset}"
                        )
                        if selected_pcd:
                            visualize_single_pointcloud(selected_pcd)
                    else:
                        # å¤šæ–‡ä»¶å¯¹æ¯”å¯è§†åŒ–
                        visualize_multiple_pointclouds(pcd_files)
            
            if bag_files:
                st.subheader("ğŸ’ ROS Bagæ–‡ä»¶")
                for bag_file in bag_files:
                    st.write(f"**æ–‡ä»¶**: {os.path.basename(bag_file)}")
                    st.info("ROS Bagæ•°æ®è§£æåŠŸèƒ½å¼€å‘ä¸­...")

def delete_dataset(dataset_id):
    """åˆ é™¤æ•°æ®é›†"""
    try:
        # è·å–æ–‡ä»¶è·¯å¾„
        conn = sqlite3.connect('data.db')
        c = conn.cursor()
        c.execute("SELECT file_paths FROM datasets WHERE id = ?", (dataset_id,))
        result = c.fetchone()
        
        if result and result[0]:
            file_paths = str(result[0]).split(",")
            # åˆ é™¤æ–‡ä»¶å’Œç›®å½•
            for file_path in file_paths:
                if os.path.exists(file_path):
                    os.remove(file_path)
            
            # åˆ é™¤ç›®å½•ï¼ˆå¦‚æœä¸ºç©ºï¼‰
            if file_paths:
                dataset_dir = os.path.dirname(file_paths[0])
                if os.path.exists(dataset_dir) and not os.listdir(dataset_dir):
                    os.rmdir(dataset_dir)
        
        # ä»æ•°æ®åº“åˆ é™¤è®°å½•
        c.execute("DELETE FROM datasets WHERE id = ?", (dataset_id,))
        conn.commit()
        conn.close()
        
        st.success("æ•°æ®é›†åˆ é™¤æˆåŠŸ")
    except Exception as e:
        st.error(f"åˆ é™¤å¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title="æ— äººé©¾é©¶æ•°æ®å¹³å°",
        page_icon="ğŸš—",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # åˆå§‹åŒ–æ•°æ®åº“
    init_database()
    init_auth_database()
    
    # æ£€æŸ¥ç”¨æˆ·è®¤è¯
    if not check_authentication():
        show_auth_page()
        return
    
    # æ˜¾ç¤ºç”¨æˆ·ä¿¡æ¯
    show_user_info()
    
    # ä¾§è¾¹æ å¯¼èˆª
    st.sidebar.title("ğŸš— å¯¼èˆªèœå•")
    page = st.sidebar.selectbox(
        "é€‰æ‹©åŠŸèƒ½",
        ["é¦–é¡µ", "æ•°æ®ä¸Šä¼ ", "æ•°æ®æµè§ˆ", "æ•°æ®å¯è§†åŒ–"],
        help="é€‰æ‹©è¦ä½¿ç”¨çš„åŠŸèƒ½æ¨¡å—"
    )
    
    # ä¾§è¾¹æ ä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“Š å¹³å°ä¿¡æ¯")
    
    try:
        conn = sqlite3.connect('data.db')
        c = conn.cursor()
        c.execute("SELECT COUNT(*) FROM datasets")
        count = c.fetchone()[0]
        conn.close()
        st.sidebar.metric("æ•°æ®é›†æ•°é‡", count)
    except:
        st.sidebar.metric("æ•°æ®é›†æ•°é‡", "0")
    
    st.sidebar.markdown("### ğŸ”— å¿«é€Ÿé“¾æ¥")
    st.sidebar.markdown("[ğŸ“š ä½¿ç”¨æ–‡æ¡£](#)")
    st.sidebar.markdown("[ğŸ’¡ åŠŸèƒ½å»ºè®®](#)")
    st.sidebar.markdown("[ğŸ› é—®é¢˜åé¦ˆ](#)")
    
    # é¡µé¢è·¯ç”±
    if page == "é¦–é¡µ":
        show_homepage()
    elif page == "æ•°æ®ä¸Šä¼ ":
        show_upload_page()
    elif page == "æ•°æ®æµè§ˆ":
        show_browse_page()
    elif page == "æ•°æ®å¯è§†åŒ–":
        show_visualization_page()

if __name__ == "__main__":
    main()