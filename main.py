import streamlit as st
import sqlite3
import os
from datetime import datetime
import pandas as pd
import plotly.express as px
from PIL import Image
import yaml
import json
import cv2
import numpy as np

def init_database():
    """åˆå§‹åŒ–SQLiteæ•°æ®åº“"""
    conn = sqlite3.connect('data.db')
    c = conn.cursor()
    
    # åˆ›å»ºæ•°æ®é›†è¡¨
    c.execute('''
        CREATE TABLE IF NOT EXISTS datasets (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            description TEXT,
            upload_time TEXT,
            file_count INTEGER DEFAULT 0,
            file_paths TEXT
        )
    ''')
    
    conn.commit()
    conn.close()

def show_homepage():
    """æ˜¾ç¤ºé¦–é¡µ"""
    st.title("ğŸš— æ— äººé©¾é©¶æ•°æ®ç®¡ç†å¹³å°")
    
    # å¹³å°ä»‹ç»
    st.markdown("""
    ## æ¬¢è¿ä½¿ç”¨æ— äººé©¾é©¶æ•°æ®ç®¡ç†å¹³å° 
    
    è¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºç®¡ç†å’Œå…±äº«æ— äººé©¾é©¶ç›¸å…³å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®çš„å¹³å°ï¼Œæ”¯æŒï¼š
    
    ### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½
    - ğŸ“¤ **æ•°æ®ä¸Šä¼ **: æ”¯æŒæ¿€å…‰é›·è¾¾ã€æ‘„åƒå¤´ã€GPSã€IMUç­‰ä¼ æ„Ÿå™¨æ•°æ®
    - ğŸ“ **æ•°æ®æµè§ˆ**: ä¾¿æ·çš„æ•°æ®é›†ç®¡ç†å’Œæ–‡ä»¶æµè§ˆ
    - ğŸ“ˆ **æ•°æ®å¯è§†åŒ–**: ç›´è§‚çš„æ•°æ®å¯è§†åŒ–å’Œåˆ†æå·¥å…·
    
    ### ğŸ“Š æ”¯æŒçš„æ•°æ®æ ¼å¼
    - **ROSæ•°æ®**: .bag
    - **ç‚¹äº‘æ•°æ®**: .pcd
    - **å›¾åƒæ•°æ®**: .png, .jpg
    - **é…ç½®æ–‡ä»¶**: .yaml, .yml
    - **ä¼ æ„Ÿå™¨æ•°æ®**: .csv, .json
    
    ### ğŸ¯ ç›®æ ‡ç”¨æˆ·
    - è‡ªåŠ¨é©¾é©¶ç ”ç©¶äººå‘˜
    - é«˜æ ¡å­¦ç”Ÿå’Œæ•™å¸ˆ  
    - ç®—æ³•å·¥ç¨‹å¸ˆ
    - æ•°æ®ç§‘å­¦å®¶
    """)
    
    # ç»Ÿè®¡ä¿¡æ¯
    conn = sqlite3.connect('data.db')
    c = conn.cursor()
    c.execute("SELECT COUNT(*) FROM datasets")
    dataset_count = c.fetchone()[0]
    conn.close()
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ•°æ®é›†æ€»æ•°", dataset_count)
    with col2:
        st.metric("æ”¯æŒæ ¼å¼", "6ç§")
    with col3:
        st.metric("åœ¨çº¿ç”¨æˆ·", "1")

def show_upload_page():
    """æ˜¾ç¤ºæ•°æ®ä¸Šä¼ é¡µé¢"""
    st.title("ğŸ“¤ æ•°æ®ä¸Šä¼ ")
    
    # æ•°æ®é›†ä¿¡æ¯
    dataset_name = st.text_input("æ•°æ®é›†åç§°", placeholder="è¯·è¾“å…¥æ•°æ®é›†åç§°")
    dataset_desc = st.text_area("æ•°æ®é›†æè¿°", placeholder="è¯·æè¿°æ•°æ®é›†çš„å†…å®¹å’Œç”¨é€”")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "é€‰æ‹©æ–‡ä»¶",
        accept_multiple_files=True,
        type=['bag', 'pcd', 'png', 'jpg', 'yaml', 'yml', 'csv', 'json'],
        help="æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š.bag, .pcd, .png, .jpg, .yaml, .yml, .csv, .json"
    )
    
    if uploaded_files:
        st.subheader("æ–‡ä»¶é¢„è§ˆ")
        for file in uploaded_files:
            with st.expander(f"ğŸ“„ {file.name}"):
                st.write(f"æ–‡ä»¶å¤§å°: {file.size} bytes")
                st.write(f"æ–‡ä»¶ç±»å‹: {file.type}")
    
    if st.button("ä¸Šä¼ æ•°æ®é›†", type="primary") and dataset_name and uploaded_files:
        with st.spinner("æ­£åœ¨ä¸Šä¼ æ–‡ä»¶..."):
            try:
                # åˆ›å»ºå­˜å‚¨ç›®å½•
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                dataset_dir = f"datasets/{dataset_name}_{timestamp}"
                os.makedirs(dataset_dir, exist_ok=True)
                
                # ä¿å­˜æ–‡ä»¶
                file_paths = []
                for file in uploaded_files:
                    file_path = os.path.join(dataset_dir, file.name)
                    with open(file_path, "wb") as f:
                        f.write(file.getvalue())
                    file_paths.append(file_path)
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                conn = sqlite3.connect('data.db')
                c = conn.cursor()
                c.execute('''
                    INSERT INTO datasets (name, description, upload_time, file_count, file_paths)
                    VALUES (?, ?, ?, ?, ?)
                ''', (
                    dataset_name,
                    dataset_desc,
                    datetime.now().isoformat(),
                    len(file_paths),
                    ",".join(file_paths)
                ))
                conn.commit()
                conn.close()
                
                st.success(f"âœ… ä¸Šä¼ æˆåŠŸï¼å…±{len(file_paths)}ä¸ªæ–‡ä»¶")
                st.balloons()
                
            except Exception as e:
                st.error(f"ä¸Šä¼ å¤±è´¥: {str(e)}")

def show_browse_page():
    """æ˜¾ç¤ºæ•°æ®æµè§ˆé¡µé¢"""
    st.title("ğŸ“ æ•°æ®æµè§ˆ")
    
    # ä»æ•°æ®åº“è·å–æ•°æ®é›†åˆ—è¡¨
    conn = sqlite3.connect('data.db')
    datasets = pd.read_sql_query("SELECT * FROM datasets ORDER BY upload_time DESC", conn)
    conn.close()
    
    if datasets.empty:
        st.info("æš‚æ— æ•°æ®é›†ï¼Œè¯·å…ˆä¸Šä¼ æ•°æ®")
        return
    
    # æœç´¢åŠŸèƒ½
    search_term = st.text_input("ğŸ” æœç´¢æ•°æ®é›†", placeholder="è¾“å…¥æ•°æ®é›†åç§°è¿›è¡Œæœç´¢")
    if search_term:
        datasets = datasets[datasets['name'].str.contains(search_term, case=False, na=False)]
    
    # æ˜¾ç¤ºæ•°æ®é›†åˆ—è¡¨
    for _, dataset in datasets.iterrows():
        with st.expander(f"ğŸ“Š {dataset['name']} ({dataset['file_count']} ä¸ªæ–‡ä»¶)"):
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.write(f"**æè¿°**: {dataset['description'] or 'æ— æè¿°'}")
                st.write(f"**ä¸Šä¼ æ—¶é—´**: {pd.to_datetime(dataset['upload_time']).strftime('%Y-%m-%d %H:%M:%S')}")
                
                # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
                if dataset['file_paths']:
                    file_paths = dataset['file_paths'].split(",")
                    st.write("**æ–‡ä»¶åˆ—è¡¨**:")
                    for file_path in file_paths:
                        if os.path.exists(file_path):
                            file_size = os.path.getsize(file_path)
                            st.write(f"  - {os.path.basename(file_path)} ({file_size} bytes)")
                        else:
                            st.write(f"  - {os.path.basename(file_path)} (æ–‡ä»¶ä¸å­˜åœ¨)")
            
            with col2:
                if st.button(f"æŸ¥çœ‹è¯¦æƒ…", key=f"view_{dataset['id']}"):
                    st.session_state.selected_dataset_id = dataset['id']
                if st.button(f"åˆ é™¤æ•°æ®é›†", key=f"delete_{dataset['id']}", type="secondary"):
                    if st.session_state.get(f"confirm_delete_{dataset['id']}", False):
                        delete_dataset(dataset['id'])
                        st.rerun()
                    else:
                        st.session_state[f"confirm_delete_{dataset['id']}"] = True
                        st.warning("å†æ¬¡ç‚¹å‡»ç¡®è®¤åˆ é™¤")

def show_visualization_page():
    """æ˜¾ç¤ºæ•°æ®å¯è§†åŒ–é¡µé¢"""
    st.title("ğŸ“ˆ æ•°æ®å¯è§†åŒ–")
    
    # è·å–æ•°æ®é›†åˆ—è¡¨
    conn = sqlite3.connect('data.db')
    datasets = pd.read_sql_query("SELECT id, name FROM datasets", conn)
    conn.close()
    
    if datasets.empty:
        st.info("æš‚æ— æ•°æ®é›†å¯è§†åŒ–")
        return
    
    # é€‰æ‹©æ•°æ®é›†
    dataset_options = dict(zip(datasets['id'], datasets['name']))
    selected_dataset = st.selectbox(
        "é€‰æ‹©æ•°æ®é›†",
        options=list(dataset_options.keys()),
        format_func=lambda x: dataset_options[x]
    )
    
    if selected_dataset:
        # è·å–é€‰ä¸­æ•°æ®é›†çš„æ–‡ä»¶
        conn = sqlite3.connect('data.db')
        c = conn.cursor()
        c.execute("SELECT file_paths FROM datasets WHERE id = ?", (selected_dataset,))
        result = c.fetchone()
        conn.close()
        
        if result and result[0]:
            file_paths = result[0].split(",")
            
            # æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç±»
            image_files = [f for f in file_paths if f.endswith(('.png', '.jpg', '.jpeg'))]
            csv_files = [f for f in file_paths if f.endswith('.csv')]
            yaml_files = [f for f in file_paths if f.endswith(('.yaml', '.yml'))]
            json_files = [f for f in file_paths if f.endswith('.json')]
            pcd_files = [f for f in file_paths if f.endswith('.pcd')]
            bag_files = [f for f in file_paths if f.endswith('.bag')]
            
            # æ˜¾ç¤ºå›¾åƒæ•°æ®
            if image_files:
                st.subheader("ğŸ–¼ï¸ å›¾åƒæ•°æ®")
                cols = st.columns(3)
                for i, img_path in enumerate(image_files[:9]):  # æœ€å¤šæ˜¾ç¤º9å¼ 
                    with cols[i % 3]:
                        if os.path.exists(img_path):
                            try:
                                image = Image.open(img_path)
                                st.image(image, caption=os.path.basename(img_path), use_column_width=True)
                            except Exception as e:
                                st.error(f"æ— æ³•æ˜¾ç¤ºå›¾åƒ: {e}")
            
            # æ˜¾ç¤ºCSVæ•°æ®
            if csv_files:
                st.subheader("ğŸ“Š æ•°æ®æ–‡ä»¶")
                for csv_file in csv_files:
                    if os.path.exists(csv_file):
                        try:
                            df = pd.read_csv(csv_file)
                            st.write(f"**æ–‡ä»¶**: {os.path.basename(csv_file)}")
                            st.write(f"**æ•°æ®å½¢çŠ¶**: {df.shape}")
                            st.dataframe(df.head(100))  # åªæ˜¾ç¤ºå‰100è¡Œ
                            
                            # ç®€å•ç»Ÿè®¡å›¾è¡¨
                            numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
                            if len(numeric_cols) >= 2:
                                col1, col2 = st.columns(2)
                                with col1:
                                    fig = px.scatter(df, x=numeric_cols[0], y=numeric_cols[1])
                                    st.plotly_chart(fig, use_container_width=True)
                                with col2:
                                    fig = px.histogram(df, x=numeric_cols[0])
                                    st.plotly_chart(fig, use_container_width=True)
                        except Exception as e:
                            st.error(f"æ— æ³•è¯»å–CSVæ–‡ä»¶: {e}")
            
            # æ˜¾ç¤ºYAMLé…ç½®
            if yaml_files:
                st.subheader("âš™ï¸ é…ç½®æ–‡ä»¶")
                for yaml_file in yaml_files:
                    if os.path.exists(yaml_file):
                        try:
                            with open(yaml_file, 'r', encoding='utf-8') as f:
                                yaml_data = yaml.safe_load(f)
                            st.write(f"**æ–‡ä»¶**: {os.path.basename(yaml_file)}")
                            st.json(yaml_data)
                        except Exception as e:
                            st.error(f"æ— æ³•è¯»å–YAMLæ–‡ä»¶: {e}")
            
            # æ˜¾ç¤ºJSONæ•°æ®
            if json_files:
                st.subheader("ğŸ“‹ JSONæ•°æ®")
                for json_file in json_files:
                    if os.path.exists(json_file):
                        try:
                            with open(json_file, 'r', encoding='utf-8') as f:
                                json_data = json.load(f)
                            st.write(f"**æ–‡ä»¶**: {os.path.basename(json_file)}")
                            st.json(json_data)
                        except Exception as e:
                            st.error(f"æ— æ³•è¯»å–JSONæ–‡ä»¶: {e}")
            
            # å…¶ä»–æ–‡ä»¶ç±»å‹æç¤º
            if pcd_files:
                st.subheader("ğŸ“¡ ç‚¹äº‘æ•°æ®")
                for pcd_file in pcd_files:
                    st.write(f"**æ–‡ä»¶**: {os.path.basename(pcd_file)}")
                    st.info("ç‚¹äº‘æ•°æ®å¯è§†åŒ–åŠŸèƒ½å¼€å‘ä¸­...")
            
            if bag_files:
                st.subheader("ğŸ’ ROS Bagæ–‡ä»¶")
                for bag_file in bag_files:
                    st.write(f"**æ–‡ä»¶**: {os.path.basename(bag_file)}")
                    st.info("ROS Bagæ•°æ®è§£æåŠŸèƒ½å¼€å‘ä¸­...")

def delete_dataset(dataset_id):
    """åˆ é™¤æ•°æ®é›†"""
    try:
        # è·å–æ–‡ä»¶è·¯å¾„
        conn = sqlite3.connect('data.db')
        c = conn.cursor()
        c.execute("SELECT file_paths FROM datasets WHERE id = ?", (dataset_id,))
        result = c.fetchone()
        
        if result and result[0]:
            file_paths = result[0].split(",")
            # åˆ é™¤æ–‡ä»¶å’Œç›®å½•
            for file_path in file_paths:
                if os.path.exists(file_path):
                    os.remove(file_path)
            
            # åˆ é™¤ç›®å½•ï¼ˆå¦‚æœä¸ºç©ºï¼‰
            if file_paths:
                dataset_dir = os.path.dirname(file_paths[0])
                if os.path.exists(dataset_dir) and not os.listdir(dataset_dir):
                    os.rmdir(dataset_dir)
        
        # ä»æ•°æ®åº“åˆ é™¤è®°å½•
        c.execute("DELETE FROM datasets WHERE id = ?", (dataset_id,))
        conn.commit()
        conn.close()
        
        st.success("æ•°æ®é›†åˆ é™¤æˆåŠŸ")
    except Exception as e:
        st.error(f"åˆ é™¤å¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title="æ— äººé©¾é©¶æ•°æ®å¹³å°",
        page_icon="ğŸš—",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # åˆå§‹åŒ–æ•°æ®åº“
    init_database()
    
    # ä¾§è¾¹æ å¯¼èˆª
    st.sidebar.title("ğŸš— å¯¼èˆªèœå•")
    page = st.sidebar.selectbox(
        "é€‰æ‹©åŠŸèƒ½",
        ["é¦–é¡µ", "æ•°æ®ä¸Šä¼ ", "æ•°æ®æµè§ˆ", "æ•°æ®å¯è§†åŒ–"],
        help="é€‰æ‹©è¦ä½¿ç”¨çš„åŠŸèƒ½æ¨¡å—"
    )
    
    # ä¾§è¾¹æ ä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“Š å¹³å°ä¿¡æ¯")
    
    try:
        conn = sqlite3.connect('data.db')
        c = conn.cursor()
        c.execute("SELECT COUNT(*) FROM datasets")
        count = c.fetchone()[0]
        conn.close()
        st.sidebar.metric("æ•°æ®é›†æ•°é‡", count)
    except:
        st.sidebar.metric("æ•°æ®é›†æ•°é‡", "0")
    
    st.sidebar.markdown("### ğŸ”— å¿«é€Ÿé“¾æ¥")
    st.sidebar.markdown("[ğŸ“š ä½¿ç”¨æ–‡æ¡£](#)")
    st.sidebar.markdown("[ğŸ’¡ åŠŸèƒ½å»ºè®®](#)")
    st.sidebar.markdown("[ğŸ› é—®é¢˜åé¦ˆ](#)")
    
    # é¡µé¢è·¯ç”±
    if page == "é¦–é¡µ":
        show_homepage()
    elif page == "æ•°æ®ä¸Šä¼ ":
        show_upload_page()
    elif page == "æ•°æ®æµè§ˆ":
        show_browse_page()
    elif page == "æ•°æ®å¯è§†åŒ–":
        show_visualization_page()

if __name__ == "__main__":
    main()