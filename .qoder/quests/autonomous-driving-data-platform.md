# æ— äººé©¾é©¶æ•°æ®ç®¡ç†å¹³å°è®¾è®¡æ–‡æ¡£

## 1. æ¦‚è¿°

### 1.1 é¡¹ç›®ç®€ä»‹
æ— äººé©¾é©¶æ•°æ®ç®¡ç†å¹³å°æ˜¯ä¸€ä¸ªç±»ä¼¼GitHubçš„å¼€æºæ•°æ®å…±äº«å¹³å°ï¼Œä¸“é—¨ç”¨äºç®¡ç†å’Œå…±äº«æ— äººé©¾é©¶ç›¸å…³çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®ã€‚å¹³å°æ”¯æŒROS Bagã€PCDç‚¹äº‘ã€PNGå›¾åƒå’ŒYAMLå¤–å‚æ ‡å®šæ–‡ä»¶çš„ä¸Šä¼ ã€ä¸‹è½½ã€å­˜å‚¨ã€å¤„ç†å’Œå¯è§†åŒ–ã€‚

### 1.2 æ ¸å¿ƒä»·å€¼
- ä¸ºæ— äººé©¾é©¶ç ”ç©¶æä¾›ç»Ÿä¸€çš„æ•°æ®å…±äº«å¹³å°
- æ”¯æŒROSç”Ÿæ€ç³»ç»Ÿçš„æ•°æ®æ ¼å¼
- æä¾›ç›´è§‚çš„æ•°æ®å¯è§†åŒ–å’Œåˆ†æå·¥å…·
- é™ä½æ•°æ®è·å–å’Œå¤„ç†çš„æŠ€æœ¯é—¨æ§›

### 1.3 ç›®æ ‡ç”¨æˆ·
- è‡ªåŠ¨é©¾é©¶ç ”ç©¶äººå‘˜
- é«˜æ ¡å­¦ç”Ÿå’Œæ•™å¸ˆ
- ç®—æ³•å·¥ç¨‹å¸ˆ
- æ•°æ®ç§‘å­¦å®¶

## 2. æŠ€æœ¯æ ˆä¸ä¾èµ–

### 2.1 å‰ç«¯æŠ€æœ¯æ ˆ
- **æ¡†æ¶**: Streamlit
- **æ•°æ®å¯è§†åŒ–**: 
  - Plotlyï¼ˆå›¾è¡¨å’Œ3Dç‚¹äº‘å¯è§†åŒ–ï¼‰
  - Matplotlibï¼ˆç®€å•å›¾è¡¨ï¼‰
- **æ–‡ä»¶å¤„ç†**: pandas
- **ROSæ•°æ®å¤„ç†**: rosbag, rospyï¼ˆç”¨äºrosbagè§£æï¼‰
- **ç‚¹äº‘å¤„ç†**: open3dï¼ˆç‚¹äº‘å¯è§†åŒ–å’Œå¤„ç†ï¼‰
- **å›¾åƒå¤„ç†**: PIL, opencv-python
- **é…ç½®æ–‡ä»¶å¤„ç†**: PyYAML

### 2.2 åç«¯å­˜å‚¨
- **æ•°æ®åº“**: SQLiteï¼ˆæœ¬åœ°æ–‡ä»¶æ•°æ®åº“ï¼Œæ— éœ€å®‰è£…é…ç½®ï¼‰
- **æ–‡ä»¶å­˜å‚¨**: æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ
- **ç”¨æˆ·è®¤è¯**: Streamlit Session Stateï¼ˆç®€å•ä¼šè¯ç®¡ç†ï¼‰

### 2.3 æ•°æ®å¤„ç†
- **ROSæ•°æ®**: rosbagè§£æå’Œtopicæå–
- **ç‚¹äº‘å¤„ç†**: PCDæ–‡ä»¶è¯»å–å’Œ3Då¯è§†åŒ–
- **å›¾åƒå¤„ç†**: PNGæ–‡ä»¶æ˜¾ç¤ºå’ŒåŸºæœ¬å¤„ç†
- **é…ç½®æ–‡ä»¶**: YAMLå¤–å‚æ ‡å®šæ•°æ®è§£æ
- **æ”¯æŒçš„æ•°æ®æ ¼å¼**: 
  - ROSæ•°æ®: .bag
  - ç‚¹äº‘: .pcd
  - å›¾åƒ: .png, .jpg
  - é…ç½®: .yaml, .yml

## 3. ç®€åŒ–åº”ç”¨æ¶æ„

### 3.1 å•é¡µé¢Streamlitåº”ç”¨

```python
# main.py - ä¸»åº”ç”¨æ–‡ä»¶
import streamlit as st
import sqlite3
import os
from datetime import datetime
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from PIL import Image
import open3d as o3d
import numpy as np
import yaml
import rosbag

def main():
    st.set_page_config(
        page_title="æ— äººé©¾é©¶æ•°æ®å¹³å°",
        page_icon="ğŸš—",
        layout="wide"
    )
    
    # åˆå§‹åŒ–æ•°æ®åº“
    init_database()
    
    # ä¾§è¾¹æ å¯¼èˆª
    page = st.sidebar.selectbox(
        "é€‰æ‹©åŠŸèƒ½",
        ["é¦–é¡µ", "æ•°æ®ä¸Šä¼ ", "æ•°æ®æµè§ˆ", "æ•°æ®å¯è§†åŒ–"]
    )
    
    if page == "é¦–é¡µ":
        show_homepage()
    elif page == "æ•°æ®ä¸Šä¼ ":
        show_upload_page()
    elif page == "æ•°æ®æµè§ˆ":
        show_browse_page()
    elif page == "æ•°æ®å¯è§†åŒ–":
        show_visualization_page()

def init_database():
    """åˆå§‹åŒ–SQLiteæ•°æ®åº“"""
    conn = sqlite3.connect('data.db')
    c = conn.cursor()
    
    # åˆ›å»ºæ•°æ®é›†è¡¨
    c.execute('''
        CREATE TABLE IF NOT EXISTS datasets (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            description TEXT,
            upload_time TEXT,
            file_count INTEGER DEFAULT 0,
            file_paths TEXT,
            data_types TEXT
        )
    ''')
    
    conn.commit()
    conn.close()
```

### 3.2 æ ¸å¿ƒåŠŸèƒ½å®ç°

#### 3.2.1 æ•°æ®ä¸Šä¼ é¡µé¢
```python
def show_upload_page():
    st.title("ğŸ“¤ æ•°æ®ä¸Šä¼ ")
    
    # æ•°æ®é›†ä¿¡æ¯
    dataset_name = st.text_input("æ•°æ®é›†åç§°")
    dataset_desc = st.text_area("æ•°æ®é›†æè¿°")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "é€‰æ‹©æ–‡ä»¶",
        accept_multiple_files=True,
        type=['bag', 'pcd', 'png', 'jpg', 'yaml', 'yml']
    )
    
    if st.button("ä¸Šä¼ æ•°æ®é›†") and dataset_name and uploaded_files:
        # åˆ›å»ºå­˜å‚¨ç›®å½•
        dataset_dir = f"datasets/{dataset_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.makedirs(dataset_dir, exist_ok=True)
        
        # ä¿å­˜æ–‡ä»¶å¹¶åˆ†ç±»å¤„ç†
        file_paths = []
        data_types = []
        
        for file in uploaded_files:
            file_path = os.path.join(dataset_dir, file.name)
            with open(file_path, "wb") as f:
                f.write(file.getvalue())
            file_paths.append(file_path)
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹è¿›è¡Œåˆæ­¥å¤„ç†å’Œåˆ†ç±»
            file_ext = file.name.lower().split('.')[-1]
            if file_ext == 'bag':
                process_rosbag(file_path)
                data_types.append('rosbag')
            elif file_ext == 'pcd':
                process_pointcloud(file_path)
                data_types.append('pointcloud')
            elif file_ext in ['png', 'jpg']:
                process_image(file_path)
                data_types.append('image')
            elif file_ext in ['yaml', 'yml']:
                process_calibration(file_path)
                data_types.append('calibration')
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        conn = sqlite3.connect('data.db')
        c = conn.cursor()
        c.execute('''
            INSERT INTO datasets (name, description, upload_time, file_count, file_paths, data_types)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            dataset_name,
            dataset_desc,
            datetime.now().isoformat(),
            len(file_paths),
            ",".join(file_paths),
            ",".join(data_types)
        ))
        conn.commit()
        conn.close()
        
        st.success(f"ä¸Šä¼ æˆåŠŸï¼å…±{len(file_paths)}ä¸ªæ–‡ä»¶")
        
        # æ˜¾ç¤ºæ–‡ä»¶ç±»å‹ç»Ÿè®¡
        type_counts = {}
        for dt in data_types:
            type_counts[dt] = type_counts.get(dt, 0) + 1
        st.json(type_counts)
```

#### 3.2.2 æ•°æ®å¯è§†åŒ–é¡µé¢
```python
def show_visualization_page():
    st.title("ğŸ“ˆ æ•°æ®å¯è§†åŒ–")
    
    # è·å–æ•°æ®é›†åˆ—è¡¨
    conn = sqlite3.connect('data.db')
    datasets = pd.read_sql_query("SELECT id, name FROM datasets", conn)
    conn.close()
    
    if datasets.empty:
        st.info("æš‚æ— æ•°æ®é›†å¯è§†åŒ–")
        return
    
    # é€‰æ‹©æ•°æ®é›†
    selected_dataset = st.selectbox(
        "é€‰æ‹©æ•°æ®é›†",
        datasets['id'].tolist(),
        format_func=lambda x: datasets[datasets['id']==x]['name'].iloc[0]
    )
    
    if selected_dataset:
        # è·å–é€‰ä¸­æ•°æ®é›†çš„æ–‡ä»¶
        conn = sqlite3.connect('data.db')
        c = conn.cursor()
        c.execute("SELECT file_paths FROM datasets WHERE id = ?", (selected_dataset,))
        result = c.fetchone()
        conn.close()
        
        if result:
            file_paths = result[0].split(",")
            
            # æ˜¾ç¤ºä¸åŒç±»å‹çš„æ–‡ä»¶
            rosbag_files = [f for f in file_paths if f.endswith('.bag')]
            pcd_files = [f for f in file_paths if f.endswith('.pcd')]
            image_files = [f for f in file_paths if f.endswith(('.png', '.jpg'))]
            yaml_files = [f for f in file_paths if f.endswith(('.yaml', '.yml'))]
            
            # ROS Bagæ–‡ä»¶ä¿¡æ¯
            if rosbag_files:
                st.subheader("ğŸ’ ROS Bagæ–‡ä»¶")
                for bag_file in rosbag_files:
                    if os.path.exists(bag_file):
                        bag_info = get_rosbag_info(bag_file)
                        st.write(f"**æ–‡ä»¶**: {os.path.basename(bag_file)}")
                        st.json(bag_info)
                        
                        # æ˜¾ç¤ºå¯æå–çš„topic
                        if st.button(f"æå–æ•°æ®", key=f"extract_{os.path.basename(bag_file)}"):
                            extract_rosbag_data(bag_file)
            
            # ç‚¹äº‘æ•°æ®
            if pcd_files:
                st.subheader("ğŸ“ˆ ç‚¹äº‘æ•°æ®")
                for pcd_file in pcd_files:
                    if os.path.exists(pcd_file):
                        st.write(f"**æ–‡ä»¶**: {os.path.basename(pcd_file)}")
                        if st.button(f"æ˜¾ç¤º3Dç‚¹äº‘", key=f"pcd_{os.path.basename(pcd_file)}"):
                            show_pointcloud_3d(pcd_file)
            
            # å›¾åƒæ•°æ®
            if image_files:
                st.subheader("ğŸ–¼ï¸ å›¾åƒæ•°æ®")
                cols = st.columns(3)
                for i, img_path in enumerate(image_files[:9]):  # æœ€å¤šæ˜¾ç¤º9å¼ 
                    with cols[i % 3]:
                        if os.path.exists(img_path):
                            image = Image.open(img_path)
                            st.image(image, caption=os.path.basename(img_path), use_column_width=True)
            
            # æ ‡å®šæ–‡ä»¶
            if yaml_files:
                st.subheader("âš™ï¸ æ ‡å®šæ–‡ä»¶")
                for yaml_file in yaml_files:
                    if os.path.exists(yaml_file):
                        calib_data = load_calibration_data(yaml_file)
                        st.write(f"**æ–‡ä»¶**: {os.path.basename(yaml_file)}")
                        st.json(calib_data)
```

### 3.3 æ•°æ®å¤„ç†å‡½æ•°

#### 3.3.1 ROS Bagå¤„ç†
```python
def process_rosbag(bag_path):
    """å¤„ç†ROS Bagæ–‡ä»¶"""
    try:
        bag = rosbag.Bag(bag_path)
        info = {
            'duration': bag.get_end_time() - bag.get_start_time(),
            'messages': bag.get_message_count(),
            'topics': list(bag.get_type_and_topic_info()[1].keys())
        }
        bag.close()
        return info
    except Exception as e:
        st.error(f"å¤„ç†ROS Bagæ–‡ä»¶å‡ºé”™: {e}")
        return None

def get_rosbag_info(bag_path):
    """è·å–ROS Bagæ–‡ä»¶ä¿¡æ¯"""
    try:
        bag = rosbag.Bag(bag_path)
        info = bag.get_type_and_topic_info()
        bag_info = {
            'æŒç»­æ—¶é—´': f"{bag.get_end_time() - bag.get_start_time():.2f}ç§’",
            'æ¶ˆæ¯æ•°é‡': bag.get_message_count(),
            'Topicåˆ—è¡¨': []
        }
        
        for topic, topic_info in info[1].items():
            bag_info['Topicåˆ—è¡¨'].append({
                'topic': topic,
                'type': topic_info.msg_type,
                'count': topic_info.message_count
            })
        
        bag.close()
        return bag_info
    except Exception as e:
        return {'é”™è¯¯': str(e)}
```

#### 3.3.2 PCDç‚¹äº‘å¤„ç†
```python
def show_pointcloud_3d(pcd_path):
    """æ˜¾ç¤º3Dç‚¹äº‘"""
    try:
        pcd = o3d.io.read_point_cloud(pcd_path)
        points = np.asarray(pcd.points)
        
        # é™é‡‡æ ·ä»¥æé«˜æ€§èƒ½
        if len(points) > 10000:
            indices = np.random.choice(len(points), 10000, replace=False)
            points = points[indices]
        
        # ä½¿ç”¨Plotlyåˆ›å»º3Dæ•£ç‚¹å›¾
        fig = go.Figure(data=[go.Scatter3d(
            x=points[:, 0],
            y=points[:, 1],
            z=points[:, 2],
            mode='markers',
            marker=dict(
                size=2,
                color=points[:, 2],  # æŒ‰Zåæ ‡ç€è‰²
                colorscale='Viridis',
                showscale=True
            )
        )])
        
        fig.update_layout(
            title=f"ç‚¹äº‘æ•°æ®: {os.path.basename(pcd_path)}",
            scene=dict(
                xaxis_title="X (m)",
                yaxis_title="Y (m)",
                zaxis_title="Z (m)"
            ),
            width=800,
            height=600
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
    except Exception as e:
        st.error(f"æ˜¾ç¤ºç‚¹äº‘å¤±è´¥: {e}")
```

#### 3.3.3 YAMLæ ‡å®šæ–‡ä»¶å¤„ç†
```python
def load_calibration_data(yaml_path):
    """åŠ è½½å¹¶è§£ææ ‡å®šæ•°æ®"""
    try:
        with open(yaml_path, 'r', encoding='utf-8') as file:
            calib_data = yaml.safe_load(file)
        
        # æå–å¸¸è§çš„æ ‡å®šå‚æ•°
        parsed_data = {}
        
        if 'camera_matrix' in calib_data:
            parsed_data['ç›¸æœºå†…å‚'] = calib_data['camera_matrix']
        
        if 'distortion_coefficients' in calib_data:
            parsed_data['ç•¸å˜å‚æ•°'] = calib_data['distortion_coefficients']
            
        if 'rotation' in calib_data:
            parsed_data['æ—‹è½¬çŸ©é˜µ'] = calib_data['rotation']
            
        if 'translation' in calib_data:
            parsed_data['å¹³ç§»å‘é‡'] = calib_data['translation']
        
        # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°æ ‡å‡†æ ¼å¼ï¼Œè¿”å›åŸå§‹æ•°æ®
        if not parsed_data:
            parsed_data = calib_data
            
        return parsed_data
        
    except Exception as e:
        return {'é”™è¯¯': f"æ— æ³•è§£æYAMLæ–‡ä»¶: {e}"}
```

### 3.4 æ•°æ®å­˜å‚¨ç»“æ„

```
project/
â”œâ”€â”€ main.py              # ä¸»åº”ç”¨æ–‡ä»¶
â”œâ”€â”€ data.db             # SQLiteæ•°æ®åº“
â”œâ”€â”€ datasets/           # æ•°æ®é›†å­˜å‚¨ç›®å½•
â”‚   â”œâ”€â”€ dataset1_20240101_120000/
â”‚   â”‚   â”œâ”€â”€ data.bag    # ROS Bagæ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ scan.pcd    # ç‚¹äº‘æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ image.png   # å›¾åƒæ–‡ä»¶
â”‚   â”‚   â””â”€â”€ calib.yaml  # æ ‡å®šæ–‡ä»¶
â”‚   â””â”€â”€ dataset2_20240101_130000/
â”‚       â””â”€â”€ ...
â””â”€â”€ requirements.txt    # ä¾èµ–åˆ—è¡¨
```

### 3.5 è¿è¡Œç¯å¢ƒé…ç½®

#### requirements.txt
```
streamlit==1.29.0
pandas==2.1.4
plotly==5.17.0
Pillow==10.1.0
open3d==0.18.0
opencv-python==4.8.1.78
PyYAML==6.0.1
rosbag==1.16.0
rospkg==1.5.0
```

#### å¯åŠ¨å‘½ä»¤
```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# è¿è¡Œåº”ç”¨
streamlit run main.py
```

## 4. æ•°æ®å¤„ç†ä¸å¯è§†åŒ–

### 4.1 ç®€åŒ–æ•°æ®å¤„ç†æµç¨‹

``mermaid
graph LR
    A[æ–‡ä»¶ä¸Šä¼ ] --> B[ä¿å­˜åˆ°æœ¬åœ°]
    B --> C[å…ƒæ•°æ®æå–]
    C --> D[ä¿å­˜åˆ°SQLite]
    D --> E[é¡µé¢æ˜¾ç¤º]
```

### 4.2 æ”¯æŒçš„æ•°æ®ç±»å‹

| æ•°æ®ç±»å‹ | æ–‡ä»¶æ ¼å¼ | å¤„ç†æ–¹å¼ | å¯è§†åŒ–æ–¹å¼ |
|------------|----------|----------|------------|
| å›¾åƒæ•°æ® | JPG, PNG | ç¼©ç•¥å›¾ç”Ÿæˆ | å›¾ç‰‡å±•ç¤º |
| GPSæ•°æ® | CSV | è¯»å–åæ ‡ç‚¹ | æ•£ç‚¹å›¾ |
| ä¼ æ„Ÿå™¨æ•°æ® | CSV, JSON | æ•°å€¼åˆ†æ | çº¿å‹å›¾ã€ç›´æ–¹å›¾ |
| ç‚¹äº‘æ•°æ® | TXT | ç®€å•è¯»å– | 3Dæ•£ç‚¹å›¾ï¼ˆå¯é€‰ï¼‰ |

### 4.3 ç®€åŒ–å¯è§†åŒ–åŠŸèƒ½

#### 4.3.1 å›¾åƒå±•ç¤º
```python
def show_images(image_paths):
    st.subheader("å›¾åƒæ•°æ®")
    cols = st.columns(3)
    for i, img_path in enumerate(image_paths):
        with cols[i % 3]:
            if os.path.exists(img_path):
                image = Image.open(img_path)
                st.image(image, caption=os.path.basename(img_path))
```

#### 4.3.2 æ•°æ®å›¾è¡¨
```python
def show_data_charts(csv_path):
    df = pd.read_csv(csv_path)
    
    # åŸºæœ¬ä¿¡æ¯
    st.write(f"æ•°æ®å½¢çŠ¶: {df.shape}")
    st.dataframe(df.head())
    
    # ç®€å•å›¾è¡¨
    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
    if len(numeric_cols) >= 2:
        fig = px.scatter(df, x=numeric_cols[0], y=numeric_cols[1])
        st.plotly_chart(fig)
```

## 5. æ•°æ®å­˜å‚¨ç­–ç•¥

### 5.1 ç®€åŒ–å­˜å‚¨æ¶æ„
```mermaid
graph TB
    A[ç”¨æˆ·ä¸Šä¼ ] --> B[æœ¬åœ°æ–‡ä»¶å­˜å‚¨]
    B --> C[SQLiteå…ƒæ•°æ®]
    C --> D[Streamlitæ˜¾ç¤º]
```

### 5.2 å­˜å‚¨è·¯å¾„è§„èŒƒ
```
/datasets/
  â”œâ”€â”€ dataset1_20240101_120000/
  â”‚   â”œâ”€â”€ image1.jpg
  â”‚   â”œâ”€â”€ image2.jpg
  â”‚   â””â”€â”€ gps_data.csv
  â””â”€â”€ dataset2_20240101_130000/
      â””â”€â”€ ...
```

### 5.3 SQLiteæ•°æ®åº“ç»“æ„
```sql
CREATE TABLE datasets (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    description TEXT,
    upload_time TEXT,
    file_count INTEGER DEFAULT 0,
    file_paths TEXT  -- é€—å·åˆ†éš”çš„æ–‡ä»¶è·¯å¾„
);
```

## 6. ç®€å•æµ‹è¯•

### 6.1 åŠŸèƒ½æµ‹è¯•
```python
# test_basic.py
import os
import tempfile
import sqlite3

def test_database_creation():
    """æµ‹è¯•æ•°æ®åº“åˆ›å»º"""
    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        conn = sqlite3.connect(tmp.name)
        c = conn.cursor()
        c.execute('''
            CREATE TABLE IF NOT EXISTS datasets (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL
            )
        ''')
        conn.commit()
        conn.close()
        
        # éªŒè¯è¡¨æ˜¯å¦åˆ›å»ºæˆåŠŸ
        conn = sqlite3.connect(tmp.name)
        c = conn.cursor()
        c.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='datasets'")
        result = c.fetchone()
        assert result is not None
        conn.close()
        
        os.unlink(tmp.name)

def test_file_upload():
    """æµ‹è¯•æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½"""
    test_dir = "test_datasets"
    os.makedirs(test_dir, exist_ok=True)
    
    # æ¨¡æ‹Ÿæ–‡ä»¶ä¸Šä¼ 
    test_file = os.path.join(test_dir, "test.jpg")
    with open(test_file, "wb") as f:
        f.write(b"fake image data")
    
    # éªŒè¯æ–‡ä»¶å­˜åœ¨
    assert os.path.exists(test_file)
    
    # æ¸…ç†
    os.remove(test_file)
    os.rmdir(test_dir)
```

### 6.2 æ‰‹åŠ¨æµ‹è¯•æ­¥éª¤
1. **å®‰è£…ä¾èµ–**: `pip install -r requirements.txt`
2. **å¯åŠ¨åº”ç”¨**: `streamlit run main.py`
3. **ä¸Šä¼ æ•°æ®**: é€‰æ‹©æ•°æ®ä¸Šä¼ é¡µé¢ï¼Œä¸Šä¼ æµ‹è¯•æ–‡ä»¶
4. **æµè§ˆæ•°æ®**: æ£€æŸ¥æ•°æ®æ˜¯å¦æ­£å¸¸æ˜¾ç¤º
5. **å¯è§†åŒ–æµ‹è¯•**: éªŒè¯å›¾è¡¨å’Œå›¾åƒæ˜¾ç¤º

